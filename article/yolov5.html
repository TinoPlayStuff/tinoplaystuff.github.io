<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<link rel="stylesheet" href="//tinoplaystuff.github.io/TPS_css/main.css" tyep="text/css" />

    <title>
      yolov5 - tinoplaystuff_site_name
    </title>
<link rel="stylesheet" href="/_markdown_plugin_assets/highlight.js/atom-one-light.css" /></head>

<body>
  <div class="main">
    <nav class="navigation">
      <a href="/">
        tinoplaystuff_site_name
      </a>
    </nav>
    <article>
      <header>
        <h1 class="article-title">
          yolov5
        </h1>
        <div class="article-info">
          <div>
            <span>Created At：<time datetime="1609293263405">
                2020-12-30 09:54
              </time></span>
            <span>Updated At：<time datetime="1655087862019">
                2022-06-13 10:37
              </time></span>
          </div>
          
            <div>
              Keywords: 
                <span class="keyword">
                  yolo
                </span>
                
            </div>
            
        </div>
      </header>
      <div class="article-content markdown-body">
        <h1 id="dnn">dnn</h1>
<nav class="table-of-contents"><ul><li><a href="#dnn">dnn</a><ul><li><a href="#temp">temp</a></li><li><a href="#tips">tips</a></li><li><a href="#yolov5-61">yolov5-6.1</a><ul><li><a href="#rknn-optimize">rknn optimize</a></li></ul></li><li><a href="#yolov5-pytorch">yolov5 (pytorch)</a></li><li><a href="#yolov5-tflite">yolov5 tflite</a><ul><li><a href="#edgetpu-model">edgetpu model</a><ul><li><a href="#minimal-sample">minimal sample</a></li><li><a href="#build-edtetpu-library">build edtetpu library</a></li><li><a href="#error">error</a></li></ul></li></ul></li><li><a href="#yolov5-tensorflow">yolov5 (tensorflow)</a></li><li><a href="#yolov5-openvino">yolov5 (openvino)</a><ul><li><a href="#yv5-openvino-quantization">yv5 openvino quantization</a></li><li><a href="#log">log</a></li></ul></li><li><a href="#method">method</a></li><li><a href="#model-conversion">Model conversion</a></li><li><a href="#variation">variation</a></li></ul></li></ul></nav><hr />
<h2 id="temp">temp</h2>
<ul>
<li>version description
<ul>
<li>use yolov5-4.0 to train model
<ul>
<li>use 4.0 to convert, use post_process to explain result</li>
<li>use 4.0-tflite, need to use post_process_xx(tflite)</li>
<li>use 5.x to convert, …</li>
</ul>
</li>
</ul>
</li>
<li>get coco data
<ul>
<li>use script in yolov5</li>
<li>YOLO-Coco-Dataset-Custom-Classes-Extractor too slow to download data</li>
</ul>
</li>
<li>convert coco to yolo, extract classes interesting to us
<ul>
<li>YOLO-Coco-Dataset-Custom-Classes-Extractor has codes</li>
<li><a title="https://bit.ly/developpaper_yolov4" href="https://bit.ly/developpaper_yolov4">developpaper: yolov4 in docker with coco data</a></li>
<li><a title="https://github.com/ultralytics/JSON2YOLO" href="https://github.com/ultralytics/JSON2YOLO">https://github.com/ultralytics/JSON2YOLO</a></li>
<li>using gluon <a title="https://bit.ly/medium_coco2yolo" href="https://bit.ly/medium_coco2yolo">medium: Selecting and preparing a specific subset of images
from the COCO dataset to train YOLO Object
Detection Model</a></li>
</ul>
</li>
<li>discussion about mosaic
<ul>
<li><a title="https://www.zhihu.com/question/473350307" href="https://www.zhihu.com/question/473350307">https://www.zhihu.com/question/473350307</a></li>
<li><a title="https://github.com/ultralytics/yolov5/issues/2151" href="https://github.com/ultralytics/yolov5/issues/2151">https://github.com/ultralytics/yolov5/issues/2151</a></li>
<li>“Data Augmentation 里面需要强调的一点是： 要在训练结束前的15个 epoch 关掉 Mosaic
和 Mixup ，这对于 YOLOX 非常重要。”
<img src="/_resources/1d4ecd5a3bd04536b23aa683f6ded4b3.png" /></li>
</ul>
</li>
</ul>
<h2 id="tips">tips</h2>
<ul>
<li>parameter discussion
<ul>
<li><code>--cache disk</code>: create cache on disk, on .88, it helps (from 8’57" to 7’45")
<ul>
<li>it’l create <code>labels_npy</code> folder, better remove it for a new run</li>
</ul>
</li>
</ul>
</li>
<li>epoch, official says try 300, 600, 1200, …</li>
<li></li>
</ul>
<h2 id="yolov5-61">yolov5-6.1</h2>
<ul>
<li>install: modify requirement.txt, may encounter errors,
<ul>
<li>try to uninstall numpy first, and type command to install Cython and
pycocotools</li>
</ul>
</li>
<li>commands:
<ul>
<li><strong>get pre-trained model</strong>:<div><pre class="hljs"><code>model = torch.hub.load(<span class="hljs-string">'ultralytics/yolov5'</span>, <span class="hljs-string">'yolov5n'</span>)</code></pre></div>
</li>
<li><strong>detect</strong>:<div><pre class="hljs"><code>python detect.py --save-txt --classes 0 \
--source ../data_test/Qnap_high/yolo/images/ \
--weights pre_trained_models/yolov5n.pt --project test/example</code></pre></div>
</li>
<li><strong>export</strong>:<div><pre class="hljs"><code>python export.py --weights pre_trained_models/yolov5n.pt \
--include onnx \
--img 480 --batch 1</code></pre></div>
<ul>
<li>用 v4.0 來 export .onnx 是可行的
<ul>
<li>需在 common.py 中增加 SPPF class</li>
</ul>
</li>
</ul>
</li>
<li><strong>export (edgetpu)</strong>
<ul>
<li>[20220330] need to remove --img<div><pre class="hljs"><code> python export.py --weights pre_trained_models/yolov5n.pt \
                  --include edgetpu --batch 1</code></pre></div>
</li>
</ul>
</li>
<li><strong>train</strong><div><pre class="hljs"><code><span class="hljs-comment"># on 126</span>
python train.py --project ./runs/r4_yv5n2_480_CrowdRgbdSafety \
            --img 480 --batch-size 16 --epoch 200 \
            --data ./data/CrowdRgbdSafety_c2_1.yaml \
            --cfg ./models/yolov5n_c2.yaml \
            --hyp ./data/hyps/hyp.scratch-low.yaml \
            --weights ./pre_trained_models/yolov5n.pt \
            --multi-scale --workers 8 --resume</code></pre></div>
this is for multiple gpu<div><pre class="hljs"><code>python -m torch.distributed.launch --nproc_per_node 2 \
   train.py --project ./runs/r4_yv5n2_480_CrowdRgbdSafety \
            --img 480 --batch-size -1 --epoch 200 \
            --data ./data/CrowdRgbdSafety_c2_1.yaml \
            --cfg ./models/yolov5n_c2.yaml \
            --hyp ./data/hyps/hyp.scratch_4.yaml \
            --weights ./pre_trained_models/yolov5n.pt \
            --cache-images --multi-scale --device 1,2</code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="rknn-optimize">rknn optimize</h3>
<ul>
<li>ref:
<ul>
<li><a title="https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo" href="https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo">https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo</a>
<ul>
<li><a title="https://github.com/airockchip/yolov5" href="https://github.com/airockchip/yolov5">https://github.com/airockchip/yolov5</a></li>
<li><a title="https://github.com/EASY-EAI/yolov5" href="https://github.com/EASY-EAI/yolov5">https://github.com/EASY-EAI/yolov5</a></li>
</ul>
</li>
</ul>
</li>
<li>my step:
<ol>
<li>use relu</li>
<li>modify exporter (Detect())
<ul>
<li>this will fail the train()</li>
</ul>
</li>
<li>modify tf.py for so that tflite exporter know the relu</li>
</ol>
</li>
<li>working:
<ul>
<li>convert model on .126 (/home/tino/curr_proj/rknn_convert/demo)
<ul>
<li>using (rknn_conv) venv</li>
<li>note, currently use <code>rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]],output_tensor_type="int8")</code>, but maybe it could omit <code>output_tensor_type="int8"</code></li>
<li>sample code:<div><pre class="hljs"><code>python test_onnx.py ....../weights/best.onnx --target rk3568 &gt;&gt; log.txt</code></pre></div>
</li>
</ul>
</li>
<li><s>build application on 10.33.72.21 (admin/d9323003)</s></li>
<li>build application on 10.33.72.24:10022
<ul>
<li>docker exec -it tino_build bash</li>
<li>see “~/tino_mount/rknn_ssd_demo_static/app/build_demo.sh”
<ul>
<li>neglect the reported type of input and output nodes, just feed uint8
and ask float return.</li>
</ul>
</li>
</ul>
</li>
<li>from Carl: <a>rknn_carl</a></li>
<li>from <a title="https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo/convert_rknn_demo/yolov5/onnx_models" href="https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo/convert_rknn_demo/yolov5/onnx_models">https://github.com/rockchip-linux/rknpu2/tree/master/examples/rknn_yolov5_demo/convert_rknn_demo/yolov5/onnx_models</a>
<ul>
<li>a yolov5 example, but it’s .onnx model has different shapes to it’s readme</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="yolov5-pytorch">yolov5 (pytorch)</h2>
<ul>
<li>commands
<ul>
<li>
<p>train:</p>
<div><pre class="hljs"><code>CUDA_VISIBLE_DEVICES=<span class="hljs-string">"0"</span> python train.py --project runs05/ --img 640 \
--batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
--cfg ./models/yolov5ss2.yaml --weights runs05/exp3/weights/best.pt

CUDA_VISIBLE_DEVICES=<span class="hljs-string">"0"</span> python train.py --project runs05/ --img 640 \
--batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
--cfg ./models/yolov5ss2.yaml --resume</code></pre></div>
</li>
<li>
<p>fine tune:</p>
<div><pre class="hljs"><code>CUDA_VISIBLE_DEVICES=<span class="hljs-string">"0"</span> python train.py --project runs05/ --img 640 \ 
--batch-size 16 --epochs 20000 --data ./data/crowd_human.yaml \
--cfg ./models/yolov5ss2.yaml --hyp data/hyp.finetune_02.yaml \
--weights runs05/exp5/weights/best.pti</code></pre></div>
</li>
<li>
<p>export:</p>
<div><pre class="hljs"><code>python ./models/export.py --weights best_crowdhuman_s1.pt --img 640 \
--batch 1</code></pre></div>
</li>
<li>
<p>detect:</p>
<ul>
<li>older code:</li>
</ul>
<div><pre class="hljs"><code>python detect.py --save-txt \
--<span class="hljs-built_in">source</span> /content/Safety_Helmet_Train_dataset/score/images/train/ \
--weight weights/yolov5x.py --output inference/2/out_train</code></pre></div>
<ul>
<li>newer code:</li>
</ul>
<div><pre class="hljs"><code>python detect.py --save-txt --classes 0 \
--<span class="hljs-built_in">source</span> /content/Safety_Helmet_Train_dataset/score/images/train/ \
--weights weights/yolov5x.pt --project inference/2/out_train</code></pre></div>
</li>
</ul>
</li>
</ul>
<h2 id="yolov5-tflite">yolov5 tflite</h2>
<ul>
<li>
<p><a title="https://j.mp/34zrhS8" href="https://j.mp/34zrhS8">https://github.com/ultralytics/yolov5/issues/1090</a>
convert to tflite successfully. (Oct 7, 2020)</p>
</li>
<li>
<p><a title="https://j.mp/3pgtbyY" href="https://j.mp/3pgtbyY">https://github.com/ultralytics/yolov5/issues/232</a>
(Jun 29, 2020)</p>
<ul>
<li>
<p>describe a way to comvert to .onnx -&gt; .pb -&gt; .tflite</p>
</li>
<li>
<p><a title="https://j.mp/34RnPCD" href="https://j.mp/34RnPCD">google colab</a> example codes to
<strong>build tensorflow lite</strong></p>
<div><pre class="hljs"><code>! sudo apt install bazel
! sudo apt install g++ unzip <span class="hljs-built_in">zip</span>
! wget https://github.com/bazelbuild/bazel/releases/download/<span class="hljs-number">3.3</span><span class="hljs-number">.0</span>/bazel-<span class="hljs-number">3.3</span><span class="hljs-number">.0</span>-installer-linux-x86_64.sh
! chmod +x bazel-<span class="hljs-number">3.3</span><span class="hljs-number">.0</span>-installer-linux-x86_64.sh
! bash bazel-<span class="hljs-number">3.3</span><span class="hljs-number">.0</span>-installer-linux-x86_64.sh
! bazel build tensorflow/contrib/lite/toco:toco</code></pre></div>
</li>
<li>
<p>zldrobit suggest tf-android (#1127) here (Nov 3, 2020)</p>
</li>
</ul>
</li>
<li>
<p><a title="https://j.mp/3mDoxct" href="https://j.mp/3mDoxct">https://github.com/ultralytics/yolov5/issues/453</a>
(Jul 20, 2020)
also encounted the error while converting .onnx -&gt; .tflite</p>
<div><pre class="hljs"><code>error: <span class="hljs-string">'tf.AddV2'</span> op is neither a custom op nor a flex op</code></pre></div>
<ul>
<li>
<p>zldrobit suggest <strong>tf-export</strong> (#959) (Sep 12, 2020)</p>
</li>
<li>
<p>[<a title="https://github.com/ultralytics/yolov5/issues/453#issuecomment-692287842" href="https://github.com/ultralytics/yolov5/issues/453#issuecomment-692287842">https://github.com/ultralytics/yolov5/issues/453#issuecomment-692287842</a>]
encounted inference problem with zldrobit’s solution (if tensorflow version
not 2.3 while inference)</p>
<div><pre class="hljs"><code>ValueError: Didn<span class="hljs-string">'t find op for builtin opcode '</span>RESIZE_NEAREST_NEIGHBO<span class="hljs-string">R' version '</span><span class="hljs-number">3</span><span class="hljs-string">'</span></code></pre></div>
</li>
<li>
<p>[<a title="https://github.com/ultralytics/yolov5/issues/453#issuecomment-694194659" href="https://github.com/ultralytics/yolov5/issues/453#issuecomment-694194659">https://github.com/ultralytics/yolov5/issues/453#issuecomment-694194659</a>]
zldroit indicate that tflite 2.0, 2.1 and 2.2 have bug</p>
<ul>
<li>irrelevant bug (only occur with GPU), but may be a reason to build
tflite 2.3.x</li>
</ul>
</li>
</ul>
</li>
<li>
<p>[<a title="https://github.com/ultralytics/yolov5/pull/959" href="https://github.com/ultralytics/yolov5/pull/959">https://github.com/ultralytics/yolov5/pull/959</a>] (Sep 12, 2020)</p>
<ul>
<li>[<a title="https://github.com/ultralytics/yolov5/pull/959#issuecomment-694548889" href="https://github.com/ultralytics/yolov5/pull/959#issuecomment-694548889">https://github.com/ultralytics/yolov5/pull/959#issuecomment-694548889</a>]
resize_nearest_neighbor are not compatible with the edge TPU
<ul>
<li>resize_nearest_neighbor has 3D input/output limitations.
[<a title="https://github.com/ultralytics/yolov5/pull/959#issuecomment-694602286" href="https://github.com/ultralytics/yolov5/pull/959#issuecomment-694602286">https://github.com/ultralytics/yolov5/pull/959#issuecomment-694602286</a>]</li>
</ul>
</li>
</ul>
</li>
<li>
<p>onnx to tensorflow [<a title="https://www.jianshu.com/p/fd1fcde8feee" href="https://www.jianshu.com/p/fd1fcde8feee">https://www.jianshu.com/p/fd1fcde8feee</a>]</p>
<ul>
<li>
<p>做用onnx-tf轉換.onnx到.pb時，出現問題</p>
<div><pre class="hljs"><code>onnx-tf convert -i ../../yolov5_working/yolov5/best_crowdhuman_s1.onnx \
-o ../../yolov5_working/yolov5/best_crowdhuman_s1.pb  
ModuleNotFoundError: No module named <span class="hljs-string">'tensorflow_addons'</span></code></pre></div>
</li>
<li>
<p>轉至tflite時，有另一問題</p>
<div><pre class="hljs"><code>error: <span class="hljs-string">'tf.AddV2'</span> op is neither a custom op nor a flex op</code></pre></div>
<p>[<a title="https://github.com/ultralytics/yolov5/pull/959" href="https://github.com/ultralytics/yolov5/pull/959">https://github.com/ultralytics/yolov5/pull/959</a>] 似乎有解，但要tensorflow2.3
(onnx-tf建議tensorflow2.2)</p>
<ul>
<li>onnx-tf現在(20201201)也建議tensorflow2.3.1，still don’t work with onnx-tf</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>tf-android</strong> (yolov5)
[<a title="https://github.com/zldrobit/yolov5/tree/1f8499c047126d678f631b8ee73681c913c64995" href="https://github.com/zldrobit/yolov5/tree/1f8499c047126d678f631b8ee73681c913c64995">https://github.com/zldrobit/yolov5/tree/1f8499c047126d678f631b8ee73681c913c64995</a>]</p>
<ul>
<li>
<p>16-tflite</p>
<div><pre class="hljs"><code>PYTHONPATH=. python models/tf.py --weight ../model/best.pt \ 
--cfg ../model/yolov5ss2.yaml --img 640 --no-tfl-detect
python detect.py --weights ../model/best-fp16.tflite --cfg ../model/yolov5ss2.yaml \
--img 640 --<span class="hljs-built_in">source</span> ../data/273275,cd061000af95f691.jpg --tfl-detect</code></pre></div>
</li>
<li>
<p>8-tflite</p>
<div><pre class="hljs"><code>PYTHONPATH=. python models/tf.py --weights ../model/best.pt \ 
--cfg ../model/yolov5ss2.yaml --img 640 --tfl-int8 --no-tfl-detect \
--<span class="hljs-built_in">source</span> ../data/CrowdHumanYv5_100img/ --ncalib 100 

python detect.py --weights ../model/best-int8.tflite --cfg ../model/yolov5ss2.yaml \
--img 640 --<span class="hljs-built_in">source</span> ../data/273275,cd061000af95f691.jpg --tfl-int8 --tfl-detect</code></pre></div>
<div><pre class="hljs"><code>PYTHONPATH=. python models/tf.py --weight \
../../yolov5_working/yolov5/runs_yv5ss1_640_high_top/exp_25_4/weights/best_01364.pt \
--cfg ../../yolov5_working/yolov5/models/yolov5ss1.yaml \
--img 640 --tfl-int8 --<span class="hljs-built_in">source</span> \
../../yolov5_working/data/top-view-multi-person-tracking-2020-ss/train/images \
--ncalib 100</code></pre></div>
</li>
<li>
<p>[20201201] 測試時，tf-only-export 無法做uint8的偵測</p>
</li>
<li>
<p>[20210308] 發現glenn-jocher也對此有許多contribution</p>
<ul>
<li><a title="https://github.com/ultralytics/yolov5/issues/1847" href="https://github.com/ultralytics/yolov5/issues/1847">https://github.com/ultralytics/yolov5/issues/1847</a></li>
<li><a title="https://github.com/ultralytics/yolov5/issues/1981" href="https://github.com/ultralytics/yolov5/issues/1981">https://github.com/ultralytics/yolov5/issues/1981</a></li>
</ul>
</li>
<li>
<p>[20210330]</p>
<ul>
<li>convert<div><pre class="hljs"><code>PYTHONPATH=. python3  models/tf.py --weight weights/yolov5s.pt --cfg models/yolov5s.yaml --img 320 --tfl-int8 --<span class="hljs-built_in">source</span> /data/dataset/coco/coco2017/train2017 --ncalib 100

PYTHONPATH=. python3 models/tf.py \
--weight ../../yolov5_working_2888/yolov5-4.0/runs_4.0_yv5ss1_480_high_top/exp/cvt/best_00358_4.0_480.pt \
--cfg ../../yolov5_working_2888/yolov5-4.0/models/yolov5ss1.yaml \
--img 480 --tfl-int8 \
--<span class="hljs-built_in">source</span> ../../yolov5_working_2888/data/top-view-multi-person-tracking-2020_Yv5/images/train \
--ncalib 100</code></pre></div>
now need tensorflow 2.4, with 2.3.1, got:<div><pre class="hljs"><code>TFLite <span class="hljs-built_in">export</span> failure: Quantization not yet supported <span class="hljs-keyword">for</span> op:
Traceback (most recent call last):
  File <span class="hljs-string">"models/tf.py"</span>, line 479, <span class="hljs-keyword">in</span> &lt;module&gt;
    tflite_model = converter.convert()
  File <span class="hljs-string">"/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"</span>, line 830, <span class="hljs-keyword">in</span> convert
    <span class="hljs-built_in">return</span> super(TFLiteKerasModelConverterV2,
  File <span class="hljs-string">"/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"</span>, line 638, <span class="hljs-keyword">in</span> convert
    result = self._calibrate_quantize_model(result, **flags)
  File <span class="hljs-string">"/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"</span>, line 450, <span class="hljs-keyword">in</span> _calibrate_quantize_model
    <span class="hljs-built_in">return</span> calibrate_quantize.calibrate_and_quantize(
  File <span class="hljs-string">"/hdd1/tino/venv/for_yolov5_4.0/lib/python3.8/site-packages/tensorflow/lite/python/optimize/calibrator.py"</span>, line 95, <span class="hljs-keyword">in</span> calibrate_and_quantize
    <span class="hljs-built_in">return</span> self._calibrator.QuantizeModel(
RuntimeError: Quantization not yet supported <span class="hljs-keyword">for</span> op:</code></pre></div>
</li>
<li>detect<div><pre class="hljs"><code>CUDA_VISIBLE_DEVICES=<span class="hljs-string">"1"</span> python3 detect.py \
--weight ../../yolov5_working_2888/yolov5-4.0/runs_4.0_yv5ss1_480_high_top/exp/cvt/best_00358_4.0_480-int8.tflite \
--img 480 --tfl-int8 --<span class="hljs-built_in">source</span> ../../yolov5_working_2888/data_test/top</code></pre></div>
<ul>
<li>the output detail:<div><pre class="hljs"><code>[{<span class="hljs-string">'name'</span>: <span class="hljs-string">'Identity'</span>, <span class="hljs-string">'index'</span>: 424, <span class="hljs-string">'shape'</span>: array([    1, 14175,     6], dtype=int32), <span class="hljs-string">'shape_signature'</span>: array([    1, 14175,     6], dtype=int32), <span class="hljs-string">'dtype'</span>: &lt;class <span class="hljs-string">'numpy.uint8'</span>&gt;, <span class="hljs-string">'quantization'</span>: (0.008681188337504864, 2), <span class="hljs-string">'quantization_parameters'</span>: {<span class="hljs-string">'scales'</span>: array([  0.0086812], dtype=float32), <span class="hljs-string">'zero_points'</span>: array([2], dtype=int32), <span class="hljs-string">'quantized_dimension'</span>: 0}, <span class="hljs-string">'sparsity_parameters'</span>: {}}]</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>edgetpu-minimal-example</strong>
[<a title="https://github.com/Namburger/edgetpu-minimal-example" href="https://github.com/Namburger/edgetpu-minimal-example">https://github.com/Namburger/edgetpu-minimal-example</a>]</p>
<ul>
<li>
<p>to use tensorflow 2.3.1, change</p>
<div><pre class="hljs"><code>set(TENSORFLOW_COMMIT fcc4b966f1265f466e82617020af93670141b009)
<span class="hljs-comment">#set(TENSORFLOW_COMMIT d855adfc5a0195788bf5f92c3c7352e638aa1109)</span></code></pre></div>
</li>
<li>
<p>to avoid compile error</p>
<div><pre class="hljs"><code>set(OTHERS
-L/usr/lib/x86_64-linux-gnu
-ldl) 
target_link_libraries(minimal model_utils ${TF_LITE_LIB} ${TF_ET_SRC_LIB} ${OTHERS})</code></pre></div>
</li>
<li>
<p>coral::read_bmp() cause error</p>
<ul>
<li>it only accept .bmp</li>
</ul>
</li>
<li>
<p>coral::RunInference cause “Segmentation fault”</p>
<ul>
<li>it doesn’t happen with int8 model</li>
</ul>
</li>
<li>
<p>Need care nchw/nhwc</p>
</li>
<li>
<p>Need care about int8-&gt;float with int8 model</p>
</li>
<li>
<p>若用預設的tensorflow2.1.2</p>
<ul>
<li>
<p>fp32 or fp16:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ERROR: </span>Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3'
<span class="hljs-keyword">ERROR: </span>Registration failed.</code></pre></div>
</li>
<li>
<p>int8:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ERROR: </span>Didn't find op for builtin opcode 'LEAKY_RELU' version '2'
<span class="hljs-keyword">ERROR: </span>Registration failed.</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="edgetpu-model">edgetpu model</h3>
<ul>
<li>minimal sample git performs ok
<ul>
<li>originally it based on tf 2.1
(d855adfc5a0195788bf5f92c3c7352e638aa1109 20200124)
<ul>
<li>yolov5 model needs tf 2.3.1 (because the converter (tf-android))</li>
</ul>
</li>
<li>built with tf 2.3.1, with carl’s .so .a, (probabily tf 2.1)
(f394a768719a55b5c351ed1ecab2ec6f16f99dd4 20200409)
<ul>
<li>sample model: can run, identical with original (tf 2.1), cpu results
similar to gpu results
<ul>
<li>ori + cpu<div><pre class="hljs"><code>edgetpu-minimal-example_ori_tf2.3.1/build<span class="hljs-comment"># ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt</span>
------
Class: tabby, tabby cat
Score: 0.046875
------
Class: tiger cat
Score: 0.109375
------
Class: Siamese cat, Siamese
Score: 0.00390625
------
Class: Egyptian cat
Score: 0.804688
------
Class: doormat, welcome mat
Score: 0.0078125
------
Class: radiator
Score: 0.0078125
------
Class: space heater
Score: 0.0117188</code></pre></div>
</li>
<li>ori + tpu<div><pre class="hljs"><code>../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant_edgetpu.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt
ERROR: Internal: Unsupported data <span class="hljs-built_in">type</span> <span class="hljs-keyword">in</span> custom op handler: 36999120
ERROR: Node number 0 (edgetpu-custom-op) failed to prepare.

Failed to allocate tensors.
Segmentation fault</code></pre></div>
</li>
<li>with carl’s lib + cpu<div><pre class="hljs"><code>edgetpu-minimal-example_ori_tf2.3.1_carl/build<span class="hljs-comment"># ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt</span>
------
Class: tabby, tabby cat
Score: 0.046875
------
Class: tiger cat
Score: 0.109375
------
Class: Siamese cat, Siamese
Score: 0.00390625
------
Class: Egyptian cat
Score: 0.804688
------
Class: doormat, welcome mat
Score: 0.0078125
------
Class: radiator
Score: 0.0078125
------
Class: space heater
Score: 0.0117188</code></pre></div>
</li>
<li>with carl’s lib + tpu<div><pre class="hljs"><code>edgetpu-minimal-example_ori_tf2.3.1_carl/build<span class="hljs-comment"># ../out/k8/minimal ../test_data/mobilenet_v1_1.0_224_quant_edgetpu.tflite ../test_data/resized_cat.bmp ../test_data/imagenet_labels.txt</span>
------
Class: tabby, tabby cat
Score: 0.0390625
------
Class: tiger cat
Score: 0.128906
------
Class: Siamese cat, Siamese
Score: 0.00390625
------
Class: Egyptian cat
Score: 0.792969
------
Class: doormat, welcome mat
Score: 0.0078125
------
Class: radiator
Score: 0.0078125
------
Class: space heater
Score: 0.0117188</code></pre></div>
</li>
</ul>
</li>
<li>yolov5 model: can only run with carl’s lib file, but cpu - gpu results
somewhat similar
<ul>
<li><a type="text/plain" href="/_resources/be01ab5522dd4cb6b8c203705ef1f803.txt">cpu</a>
<a type="text/plain" href="/_resources/15a2fbdce4484f35a9609f21142b3030.txt">tpu</a></li>
</ul>
</li>
<li>yolov5_2020 model:
<ul>
<li>ori cpu = carl cpu != carl tpu</li>
</ul>
</li>
<li>yolov5 model:
<ul>
<li>ori cpu = carl cpu ~ carl tpu</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="minimal-sample">minimal sample</h4>
<ul>
<li>follow <a title="https://coral.ai/docs/edgetpu/compiler/#system-requirements" href="https://coral.ai/docs/edgetpu/compiler/#system-requirements">https://coral.ai/docs/edgetpu/compiler/#system-requirements</a><div><pre class="hljs"><code>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
<span class="hljs-built_in">echo</span> <span class="hljs-string">"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main"</span> | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list
sudo apt-get update
sudo apt-get install edgetpu-compiler</code></pre></div>
<div><pre class="hljs"><code>edgetpu_compiler -sa best_01364-2020_int8.tflite</code></pre></div>
option “a” for …</li>
</ul>
<h4 id="build-edtetpu-library">build edtetpu library</h4>
<ul>
<li>
<p>note:</p>
<ul>
<li>in minimial sample, libedgetpu.so.1 is pre-built, libtensorflow-lite.a
is built along with the execute</li>
<li>“tflite_runtime package”:
<ul>
<li>to execute tflite model with python, can install just the
“Tensorflow Lite interpreter”, instead of all TensorFlow packages.
The simplified Python package is so called “tflite_runtime”
[<a title="https://www.tensorflow.org/lite/guide/python" href="https://www.tensorflow.org/lite/guide/python">https://www.tensorflow.org/lite/guide/python</a>]</li>
</ul>
</li>
</ul>
</li>
<li>
<p>survey</p>
<ul>
<li>supported operations <a title="https://coral.ai/docs/edgetpu/models-intro/#supported-operations" href="https://coral.ai/docs/edgetpu/models-intro/#supported-operations">tpu operations</a>:
<ul>
<li>Operation version not supported: RESIZE_NEAREST_NEIGHBOR, LEAKY_RELU,
TRANSPOSE,</li>
<li>somewhat supported: QUANTIZE, STRIDED_SLICE</li>
</ul>
</li>
<li>a sample <a title="https://github.com/google-coral/edgetpu/issues/229#issuecomment-704576309" href="https://github.com/google-coral/edgetpu/issues/229#issuecomment-704576309">libedgetpu on raspberry pi</a>:
<ul>
<li>build libedgetpu.so ref [<a title="https://github.com/google-coral/libedgetpu/" href="https://github.com/google-coral/libedgetpu/">https://github.com/google-coral/libedgetpu/</a>]
Make sure to change the commit, then copy the libedgetpu.so
<ul>
<li>install bazel first <a title="https://docs.bazel.build/versions/master/install-ubuntu.html" href="https://docs.bazel.build/versions/master/install-ubuntu.html">install bazel</a></li>
</ul>
</li>
</ul>
</li>
<li>disscussion with yolov5 on edgetpu <a title="https://github.com/google-coral/edgetpu/issues/272" href="https://github.com/google-coral/edgetpu/issues/272">yolov5_tpu</a></li>
<li>carl’s build version: <a title="https://github.com/google-coral/libedgetpu/blob/master/workspace.bzl#L8" href="https://github.com/google-coral/libedgetpu/blob/master/workspace.bzl#L8">1</a></li>
</ul>
</li>
</ul>
<h4 id="error">error</h4>
<ul>
<li>ERROR: Didn’t find op for builtin opcode ‘TRANSPOSE_CONV’ version ‘3’
<ul>
<li><a title="https://github.com/google-coral/edgetpu/issues/147" href="https://github.com/google-coral/edgetpu/issues/147">https://github.com/google-coral/edgetpu/issues/147</a></li>
<li>best guess: tensorflow too new</li>
<li>The sweet spot is with tensorflow2.2 [20200616]</li>
</ul>
</li>
<li>TRANSPOSE
<ul>
<li><a title="https://github.com/google-coral/edgetpu/issues/193#issuecomment-718713474" href="https://github.com/google-coral/edgetpu/issues/193#issuecomment-718713474">https://github.com/google-coral/edgetpu/issues/193#issuecomment-718713474</a></li>
<li>may use keras to avoid TRANSPOSE</li>
</ul>
</li>
</ul>
<h2 id="yolov5-tensorflow">yolov5 (tensorflow)</h2>
<ul>
<li><a title="https://zhuanlan.zhihu.com/p/342522198" href="https://zhuanlan.zhihu.com/p/342522198">YoloV5的原理与实现：附TensorFlow版开源</a>
<ul>
<li><a title="https://github.com/LongxingTan/Yolov5" href="https://github.com/LongxingTan/Yolov5">https://github.com/LongxingTan/Yolov5</a></li>
</ul>
</li>
</ul>
<h2 id="yolov5-openvino">yolov5 (openvino)</h2>
<ul>
<li><a title="https://github.com/SamSamhuns/yolov5_export_cpu" href="https://github.com/SamSamhuns/yolov5_export_cpu">https://github.com/SamSamhuns/yolov5_export_cpu</a>
<ul>
<li>指令教學 pytorch -&gt; onnx -&gt; openvino</li>
</ul>
</li>
<li><a title="https://github.com/PINTO0309/PINTO_model_zoo" href="https://github.com/PINTO0309/PINTO_model_zoo">https://github.com/PINTO0309/PINTO_model_zoo</a>
<ul>
<li>seems older</li>
</ul>
</li>
<li><a title="https://github.com/ultralytics/yolov5/issues/891" href="https://github.com/ultralytics/yolov5/issues/891">https://github.com/ultralytics/yolov5/issues/891</a>
<ul>
<li><a title="https://cdrdv2.intel.com/v1/dl/getContent/633562" href="https://cdrdv2.intel.com/v1/dl/getContent/633562">https://cdrdv2.intel.com/v1/dl/getContent/633562</a>
<ul>
<li>一份intel官方文件</li>
</ul>
</li>
</ul>
</li>
<li><a title="https://blog.csdn.net/qq_35975447/article/details/117440167" href="https://blog.csdn.net/qq_35975447/article/details/117440167">https://blog.csdn.net/qq_35975447/article/details/117440167</a></li>
<li><a title="https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo" href="https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo">https://github.com/Chen-MingChang/pytorch_YOLO_OpenVINO_demo</a>
<ul>
<li>can use this for testing model</li>
</ul>
</li>
<li>newer openvino (since 2021.3) may have yolov5 adapter
<ul>
<li><a title="https://git.io/JE1uD" href="https://git.io/JE1uD">https://git.io/JE1uD</a></li>
</ul>
</li>
<li><a title="https://learnopencv.com/post-training-quantization-with-openvino-toolkit" href="https://learnopencv.com/post-training-quantization-with-openvino-toolkit">https://learnopencv.com/post-training-quantization-with-openvino-toolkit</a></li>
</ul>
<h3 id="yv5-openvino-quantization">yv5 openvino quantization</h3>
<ul>
<li>ref
<ul>
<li>實例：
<ul>
<li><a title="https://blog.csdn.net/sandmangu/article/details/120331202" href="https://blog.csdn.net/sandmangu/article/details/120331202">https://blog.csdn.net/sandmangu/article/details/120331202</a></li>
<li><a title="https://www.fatalerrors.org/a/19511zE.html" href="https://www.fatalerrors.org/a/19511zE.html">https://www.fatalerrors.org/a/19511zE.html</a></li>
</ul>
</li>
<li>prepare data:
<ul>
<li><a title="https://github.com/RapidAI/YOLO2COCO" href="https://github.com/RapidAI/YOLO2COCO">https://github.com/RapidAI/YOLO2COCO</a></li>
<li>yolox and openvino don’t know yolo data format</li>
</ul>
</li>
</ul>
</li>
<li>working method：
<ol>
<li>convert to onnx with yolov5 5.x</li>
<li>when converting to openvino,
<ul>
<li>use scale set input to [0.f, 255.f]</li>
<li>assign only one output node</li>
</ul>
</li>
<li>when quantizing,
<ul>
<li>ignore lower several nodes</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="log">log</h3>
<ul>
<li>from <a title="https://github.com/SamSamhuns/yolov5_export_cpu" href="https://github.com/SamSamhuns/yolov5_export_cpu">https://github.com/SamSamhuns/yolov5_export_cpu</a>
<ul>
<li>convert to onnx
<ul>
<li><s>from other discussions: modify export.py to use opset 10</s><br />
openvino 2021 remove resize opset-10 restriction</li>
<li>export code<div><pre class="hljs"><code>python models/export.py \
--weights r4_yv5ss2_480_CrowdRgbdSafety/exp2/weights/best.pt \
--img <span class="hljs-number">480</span> --batch <span class="hljs-number">1</span></code></pre></div>
</li>
</ul>
</li>
<li>onnx detect<div><pre class="hljs"><code>python detect_onnx.py -m image -i <span class="hljs-string">"media/2.jpg"</span> -c <span class="hljs-number">2</span> \
-ox ..<span class="hljs-regexp">/yolov5-4.0/</span>r4_yv5ss2_480_CrowdRgbdSafety<span class="hljs-regexp">/exp2/</span>weights/best.onnx</code></pre></div>
<img width="480" height="32" src="/_resources/ca86164b72dd4df0b0f7c0e664de5a83.png" class="jop-noMdConv" />
</li>
<li>convert to openvino<div><pre class="hljs"><code>python /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py \
      --progress \
      --input_shape [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">480</span>,<span class="hljs-number">480</span>] \
      --input_model ../yolov5-<span class="hljs-number">4.0</span>/r4_yv5ss2_480_CrowdRgbdSafety/exp2/weights/best.onnx \
      --output_dir models/CrowdRgbdSafety \
      --data_type half</code></pre></div>
</li>
<li>openvino detect<div><pre class="hljs"><code>python detect_openvino.py -m image -i <span class="hljs-string">"media/2.jpg"</span> \
--model_xml models/CrowdRgbdSafety/best.xml \
--model_bin models/CrowdRgbdSafety/best.bin</code></pre></div>
</li>
</ul>
</li>
</ul>
<h2 id="method">method</h2>
<ul>
<li>
<p>reading:</p>
<ul>
<li><a title="https://github.com/ultralytics/yolov5/discussions/6717" href="https://github.com/ultralytics/yolov5/discussions/6717">https://github.com/ultralytics/yolov5/discussions/6717</a></li>
</ul>
</li>
<li>
<p>loss</p>
<ul>
<li>採用 yolov3，但從code上看來不同
<ul>
<li>(先看)<a title="https://blog.csdn.net/qq_38253797/article/details/119444854" href="https://blog.csdn.net/qq_38253797/article/details/119444854">https://blog.csdn.net/qq_38253797/article/details/119444854</a></li>
<li><a title="https://www.whcsrl.com/blog/1018544" href="https://www.whcsrl.com/blog/1018544">https://www.whcsrl.com/blog/1018544</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>focus:</strong></p>
<ul>
<li>分區下採樣<br />
<img src="/_resources/1df2ecb445ab453d9f15ab9f8293d252.png" /></li>
<li>want to reduce the computation, but the performance varies on different devices.</li>
<li>removed in v6.0<br />
<a title="https://github.com/ultralytics/yolov5/issues/6257" href="https://github.com/ultralytics/yolov5/issues/6257">https://github.com/ultralytics/yolov5/issues/6257</a></li>
</ul>
</li>
</ul>
<h2 id="model-conversion">Model conversion</h2>
<ul>
<li>A page contains many models converted to various platforms
<ul>
<li>A page contains many models converted to various platforms
<ul>
<li>[<a title="https://github.com/PINTO0309/PINTO_model_zoo" href="https://github.com/PINTO0309/PINTO_model_zoo">https://github.com/PINTO0309/PINTO_model_zoo</a>]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="variation">variation</h2>
<ul>
<li>yolov5-lite
<ul>
<li><a title="https://github.com/ppogg/YOLOv5-Lite" href="https://github.com/ppogg/YOLOv5-Lite">https://github.com/ppogg/YOLOv5-Lite</a></li>
<li>ref: <a title="https://zhuanlan.zhihu.com/p/400545131" href="https://zhuanlan.zhihu.com/p/400545131">https://zhuanlan.zhihu.com/p/400545131</a></li>
<li>ref 1: <a title="https://www.eet-china.com/mp/a116564.html" href="https://www.eet-china.com/mp/a116564.html">https://www.eet-china.com/mp/a116564.html</a>
<ul>
<li>shufflenet, PAN</li>
</ul>
</li>
<li>在其上復現 picodet <a title="https://zhuanlan.zhihu.com/p/446787775" href="https://zhuanlan.zhihu.com/p/446787775">https://zhuanlan.zhihu.com/p/446787775</a></li>
</ul>
</li>
<li>airockchip
<ul>
<li><a title="https://github.com/airockchip/rknn_model_zoo" href="https://github.com/airockchip/rknn_model_zoo">https://github.com/airockchip/rknn_model_zoo</a></li>
</ul>
</li>
<li>ppyolo
<ul>
<li><a title="https://github.com/PaddlePaddle/PaddleDetection" href="https://github.com/PaddlePaddle/PaddleDetection">https://github.com/PaddlePaddle/PaddleDetection</a></li>
</ul>
</li>
</ul>
<p>…</p>
<p>#yolo</p>

      </div>
    </article>
  </div>
</body>

</html>